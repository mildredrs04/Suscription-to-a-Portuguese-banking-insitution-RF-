# -*- coding: utf-8 -*-
"""Hand in 3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NqvYozkD0XHF0mkCwb6J2psG4-3zDn1v
"""

# Commented out IPython magic to ensure Python compatibility.
#Hand in 3: Decision trees and random forests
#Name: Mildred Ram√≠rez
#ID: A01705162
#Date: 27/04/2023

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
# %matplotlib inline
from sklearn.model_selection import train_test_split 
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

from google.colab import drive

drive.mount("/content/gdrive", force_remount=True)
!pwd

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/gdrive/MyDrive/Intelligent Systems/random forest"
!ls



#Load dataset
df = pd.read_csv('bank-additional2.csv')
df

df.shape
df.info()

features = df.drop(['y'], axis=1)

for col in features: 
    print(df[col].value_counts())

df['y'].value_counts()

df.isnull().sum()

X = df.drop(['y'], axis=1)
y = df['y']

#Split dataset into train and test set
X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.33, random_state=42)

X_train.shape, X_test.shape

X_train.dtypes

# Commented out IPython magic to ensure Python compatibility.
# %pip install category_encoders

import category_encoders as ce

#Replace the catgorical values for numerical
replace = ce.OrdinalEncoder(cols=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'])

X_trainEn = replace.fit_transform(X_train)
X_testEn = replace.transform(X_test)

X_trainEn.head()
#X_testEn.head()

#Create the random forest
rn_forest = RandomForestClassifier(n_estimators=100, max_leaf_nodes=3, n_jobs=-1, random_state=42)

#Train the random forest
rn_forest.fit(X_trainEn, y_train)
y_pred = rn_forest.predict(X_testEn)

print('The model accuracy score of the random forest is: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))

rnd_forestf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=3, n_jobs=-1, random_state=42)

#Fit the model to the training set
rnd_forestf.fit(X_trainEn, y_train)

#Check the relevance of the features
feature_scores = pd.Series(rnd_forestf.feature_importances_, index=X_trainEn.columns).sort_values(ascending=False)
feature_scores

# Visualizing the feature scores
sns.barplot(x=feature_scores, y=feature_scores.index)

plt.xlabel('Score')
plt.ylabel('Features')
plt.title("Relevance of features")

plt.show()

#Declare feature and target 
X_imp = df[['duration','nr.employed','pdays','emp.var.rate','euribor3m','cons.conf.idx','cons.price.idx','contact','poutcome','previous','age','month','job']]
y_imp = df['y']

#Split dataset
X_train_imp, X_test_imp, y_train_imp, y_test_imp =  train_test_split(X_imp, y_imp, test_size=0.33, random_state=42)

#Replace categorical values
replace = ce.OrdinalEncoder(cols=['contact','month','job','poutcome'])

X_trainImp = replace.fit_transform(X_train_imp)
X_testImp = replace.transform(X_test_imp)

#Create the random forest
rnd_forest_imp = RandomForestClassifier(n_estimators=100, max_leaf_nodes=3, n_jobs=-1, random_state=42)

#Train the random forest
rnd_forest_imp.fit(X_trainImp, y_train_imp)
y_pred_imp = rnd_forest_imp.predict(X_testImp)

print('The model accuracy score of the random forest is: {0:0.4f}'. format(accuracy_score(y_test_imp, y_pred_imp)))

#Interface
value = input('Press 1 if you want to make a prediction')

while value == '1':
    income = input("\nEnter the income composition of resources: ")
    ft = np.expand_dims(np.array([income], dtype = 'float64'), axis=0)
    
    # Perform prediction
    prediction = regression.predict(ft)
    print("\nThe Life expectancy is: ", prediction)

    value = input("\nPress 1 to make another prediction, if not press 0: ")